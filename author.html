<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Use the title from a page's frontmatter if it has one -->
    <meta name="apple-mobile-web-app-capable" content="yes" /> 
    <meta name="apple-touch-fullscreen" content="yes" />
    <title>Steve Marshall</title>
    <link href="./stylesheets/reset.css" rel="stylesheet" />
    <link href="./stylesheets/grids.css" rel="stylesheet" />
    <link href="./stylesheets/typography.css" rel="stylesheet" />
    <link href="./stylesheets/site.css" rel="stylesheet" />

    <link href="https://fonts.googleapis.com/css?family=Rubik:400,500,500i,700&display=swap" rel="stylesheet">

   <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Schibsted+Grotesk:ital,wght@0,400;0,500;0,600;0,700;0,800;1,400;1,500;1,600;1,700;1,800&display=swap" rel="stylesheet">
    <link href="./images/favicon.png" rel="icon" type="image/png" />
  </head>
  <body>
  


<div class="header">

 <h1><a href="index.html">stvmrshll</a></h1>

  <ul class="nav">
    <li><a href="mailto:stv@stvmrshll.com">stv@stvmrshll.com</a></li>
  </ul>

</div>

<div id="project-nav" class="float-nav hide">
  <ul>
    <li class="index"><a href="index.html#work">&#x2637;</a></li>
    <li class="left"><a href="capture.html"><span>&#x279E;</span></a></li>
    <li><a href="phe.html">&#x279E;</a></li>
  </ul>
</div>

<div class="content big-bottom">

  <div class="section">
    <div class="c12">
      <img src="./images/authoring/hero.png" alt="Hero" loading="lazy" />
    </div>
  </div>

  <div class="section push-top-half">
    <div class="c6 s3 med-c12 med-s0">
      <p class="meta">Design Lead | 2021 | Meta</p>
      <h1>So that users could experience AR effects around their city, Meta needed to enable their Creators to make and publish location-based effects</h1>
    </div>
  </div>

  <div class="section">
    <div class="c6 s3 med-c12 med-s0">
        <p>Spark AR is a Meta-owned platform that allows anyone to create AR effects for users to access and experience at home. Meta wanted to expand this to enable the creation of AR effects that could be viewed at popular real-world locations.</p>

        <p>This project would be the first to utilize recent efforts to generate 3D maps of US cities. Along with many other parallel efforts, it also represented a major step towards the creation of the Metaverse.</p>

        <p>Although Spark was well established, the notion of AR outside of the home was new territory for Meta. As such, there were major challenges to be solved along the way, from the creation of the maps to getting creators to use them.</p>


    </div>
  </div>
</div>


<div class="content light big-top big-bottom">

  

  




   <div class="section">
    <div class="c6 s3 med-c12 med-s0">
      <h4>Understanding the requirements</h4>

      <h1>To start, I had to establish an understanding of what types of effects we would need to support the creation of</h1>

      <p>This project looked to expand Meta's AR offering beyond user's personal spaces and into public places for the first time. As such, it presented a range of possibilities and we needed to better understand what AR Creators might need from the tooling we create.</p>

      <p>To gain initial understanding, I planned and executed a design sprint that included a wide range of participants across multiple teams. This was essential to ensure we understood what both Creators and Users might want, as well as what the potential and limitations of the technology.</p>

      <p>Whilst early conversations were focused around the creation of effects that were unique to physical locations, this process led us to focusing on effects that were more of a continuation of what both Creators and Users were accustomed to. We knew this wasn't where we wanted this product to end up, but it would reduce barriers for adoption and put less requirements on the technology (that was still being developed) at launch.</p>

    </div>

  </div>

  <div class="section push-top-half images">

    <div class="c6 s3 med-c12 med-s0">
      <img src="./images/authoring/usecases.png" alt="Hero" loading="lazy" />
    </div>

    

  </div>





  <div class="section push-top-half">
    <div class="c6 s3 med-c12 med-s0 push-top-half">
      <h1>With a set of examle effects, we could analyse the locations to identify any additional considerations for their creation</h1>


      <p>Defining the type of effect we would target at launch allowed us to get specific on what needed to happen to enable their creation. The first step of which was to establish the parameters within which effects could be created.</p>

      <p>Although we were laying the groundwork for many future plans, we had to be careful to scope the problems we were trying to solve for the initial product. (When considering a future of world-scale, public AR, there are endless challenges to overcome which we were never going to solve from the outset.) However, through stackranking problems to solve, we identified several non-negotiables; one of which was safety.</p>

      <p>As Meta's experience so far had focused on private indoor locations, there was a lot to understand in terms of ensuring user safety. Along with earlier efforts to understand the technology, our workshops identified a need to define 'zones' to ensure user safety and maximize chance of the tech working.</p>



    </div>

  </div>

  <div class="section push-top-half images">

    <div class="c5 s1 med-c12 med-s0">
      <img src="./images/authoring/analysis.png" alt="Hero" loading="lazy" />
    </div>

    <div class="c5 med-c12 med-s0">
      <img src="./images/authoring/zone-types.png" alt="Hero" loading="lazy" />
    </div>

  </div>

</div>


<div class="content big-top">



   <div class="section">
    <div class="c6 s3 med-c12 med-s0">
      <h4>Mesh Requirements, Design, and Generation</h4>

      <h1>This understanding allowed us to explore the requirements of the representation of each physical location</h1>


      <p>Knowing the type of effect that might be created and the parameters in which creation would happen, we could start identifying the needs of the Creator. As this functionality would become part of the existing Spark AR platform, our main challenge was the unique canvas we would be providing (ie the 3D map of the physical location).</p>

      <p>Early assumptions had been made by the engineering teams that we would display a dense point cloud (that is used to position and display the effect) for the effect to be created around. Whilst this would have been the easiest solution, there was a question as to the quality of experience this would allow for Creators. In order to validate this, I arranged a series of light-touch interviews with various stakeholders which quickly confirmed the hypothesis - we needed to create better Creator meshes.</p>

      <p>This was not a trivial task, and not one that had been budgeted for (but we now had complete agreement that it was necessary). Made harder by the fact that the locations had already been decided, which meant we needed a solution that worked for a diverse range of environments (from intricate architecture, to non-descript alleyways, and the entire Manhatten skyline...).</p>

      <p>To solve this, I led a series of engineer investigations that provided varying solutions using different technologies. Alongside this, I explored different mesh forms myself by using OpenStreetMap data and Blender 3D. These variations assisted collaboration and communication with the eng teams and allowed me to iterate on and refine the requirements of any generated meshes.</p>

        
    </div>

  </div>
</div>


<div class="content full">

  <div class="spacer"></div>

  <ul class="filmstrip" style="margin-left: -220px;">
    <li><img src="./images/authoring/meshes/1.png" alt="mesh" loading="lazy" /></li>
    <li><img src="./images/authoring/meshes/2.png" alt="mesh" loading="lazy" /></li>
    <li><img src="./images/authoring/meshes/3.png" alt="mesh" loading="lazy" /></li>
    <li><img src="./images/authoring/meshes/4.png" alt="mesh" loading="lazy" /></li>
    <li><img src="./images/authoring/meshes/5.png" alt="mesh" loading="lazy" /></li>
    <li><img src="./images/authoring/meshes/6.png" alt="mesh" loading="lazy" /></li>
  </ul>

  <ul class="filmstrip" style="margin-left: -50px;">
    <li><img src="./images/authoring/meshes/7.png" alt="mesh" loading="lazy" /></li>
    <li><img src="./images/authoring/meshes/13.png" alt="mesh" loading="lazy" /></li>
    <li><img src="./images/authoring/meshes/9.png" alt="mesh" loading="lazy" /></li>
    <li>
      <video width="100%" muted loop autoplay>
        <source src="./images/authoring/flatiron.mov" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </li>
    <li><img src="./images/authoring/meshes/15.png" alt="mesh" loading="lazy" /></li>
    <li><img src="./images/authoring/meshes/12.png" alt="mesh" loading="lazy" /></li>
  </ul>

  <ul class="filmstrip" style="margin-left: -220px;">
    <li><img src="./images/authoring/meshes/8.png" alt="mesh" loading="lazy" /></li>
    <li><img src="./images/authoring/meshes/14.png" alt="mesh" loading="lazy" /></li>
    <li><video muted loop autoplay>
        <source src="./images/authoring/jefferson.mov" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </li>
    <li><img src="./images/authoring/meshes/10.png" alt="mesh" loading="lazy" /></li>
    <li><img src="./images/authoring/meshes/11.png" alt="mesh" loading="lazy" /></li>
    <li><img src="./images/authoring/meshes/12.png" alt="mesh" loading="lazy" /></li>
  </ul>


  <div class="spacer"></div>
</div>


<div class="content big-bottom">

  <div class="section">


    <div class="c6 s3 med-c12 med-s0">

        <p>With these design and engineer -focused explorations, I was able to start to define what the critical features were that needed to be displayed. With this, the engineering teams were able to focus their efforts on the technologies that would allow them to proceedurally generate the meshes for each location.</p>
    </div>
  </div>

  <div class="section push-top-half images">


    <div class="c8 s2 med-c12 med-s0">
      <img src="./images/authoring/mesh-requirements.png" alt="Hero" loading="lazy" />
    </div>
  </div>
</div>


<div class="content dark big-top big-bottom">


  <div class="section">
    <div class="c6 s3 med-c12 med-s0">
      <h4>Custom tooling</h4>
      <h1>To help with exploring mesh designs, I built custom tools to improve process &amp; collaboration</h1>

      <p>This was my first real foray into 3D and found myself limited by the steep learning curve of Blender and other 3D tools. Armed with some knowledge of Open Street Map data and Mapbox JS, I decided to create my own tools to assist with explorations into mesh requirements.</p>


    </div>
  </div>


  <div class="section push-top-half images">

    <div class="c5 s1 med-c12 med-s0">

      <div style="padding:40px 40px 0;">
        <video width="100%" controls style="border-radius:3px; margin: 0">
          <source src="./images/authoring/model-maker.mov" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>
    <div class="c4 med-c12 push-top-half">
      <p>The first allowed me to create instant 3D models of any location using OSM data and create custom planes by drawing on the 2D map. (I learned later that Blender has an OSM plugin that would have provided some of this, but it only took me a couple of hours to build and probably saved me days&mdash;if not weeks.)</p>
    </div>
    <div class="c5 s1 med-c12 med-s0" style="clear:both">
      <div style="padding:40px;">
      <img src="./images/authoring/mesh-designer.png" alt="Hero" />
      </div>
    </div>
    <div class="c4 med-c12 push-top-half">
<p>The second used the OSM data of our locations and provided functionality to crudely 'design' the look of the mesh. This was useful to quickly test basic styles across multiple locations, but the main benefit was it providing a mechanism to allow the engineers to be part of the design process. Using this tool, I ran workshops in which everyone involved could 'design' their ideal mesh.</p>
    </div>

  </div>



</div>


<div class="content big-top">





  <div class="section">
    <div class="c6 s3 med-c12 med-s0">
      <h4>Creator UI</h4>
      <h1>With the requirements for the mesh defined, it was time to understand it's integration to the Spark platform</h1>

      <p>With the mesh defined, we then had to consider how it would function and exist within the Spark platform. This required explorations across numerous areas, from how locations would be identified and selected, to how content would be positioned and managed on the canvas.</p>

    </div>
  </div>

  <div class="section push-top-half images">
     <div class="c8 s2 med-c12 med-s0">
      <img src="./images/authoring/thumbnail.png" alt="Hero" loading="lazy" />
      <img src="./images/authoring/explorations.png" alt="Hero" loading="lazy" />

      

    </div>

  </div>



  <div class="section push-top-half">
    <div class="c6 s3 med-c12 med-s0">
      <h1>Having explored all the potential platform features that could be beneficial, we stripped it back to define an MVP launch</h1>

      <p>As we were adding functionality to an already existing platform (managed in a different org), we had to be considerate of what changes we were going to propose. During earlier workshops, I had established a prioritized JTBD list that formed the basis for the design explorations. Now along with potential solutions, we could understand the effort required to bring these to launch.</p>

      

    </div>
  </div>
</div>

<div class="content">
  <div class="section">
    <div class="c3 s3 med-c12 med-s0">
      <p>Through this process, we opted for a heavily MVP approach; this was an unvalidated product direction and so emphasis was put on enabling the core functionality and leaning on Creator relations to assist in creation rather than aiming to streamline the experience from the outset. This had the bonus of us being able to get indepth learning from initial Creators and made sure we wouldn't interfere with any existing UX.</p>

      
    </div>
      <img src="./images/authoring/flow.png" alt="Hero" style="position:absolute; right:0; width:50%; margin-top:30px; border-radius: 0;" />

    <div class="c6 s3 med-c12 med-s0">
      <p>Although we had detailed a range of functionality to be added, the final launch spec was a very simple implementation with the goal to expand as we learnt more about how the Creators would use it.</p>
    </div>
  </div>
</div>


<div class="content">


  <div class="section push-top-half images">
  
    <div class="c8 s2 med-c12 med-s0">

        <img src="./images/authoring/ui.png" alt="Hero" loading="lazy" />

    </div>
  </div>










  <div class="section push-half">
    <div class="c6 s3 med-c12 med-s0 push-top-half">
      <h2>Impact</h2>


      <p>From the outset, this was an ambitious project that was pushing the boundaries of where Meta was creating the Metaverse. Whilst it aligned with long term visions, it sat somewhat separate of other parallel initiatives. Unfortunately, as we were preparing for launch, realignment of company goals reduced the priority of this project. As there were still considerable technical improvements required for launch, it was deemed these efforts would be more valuable on other projects.</p>

      <p>However, the work carried out allowed us to clearly identify what was required for when the technology was ready for this to launch. As the first fully defined product of it's kind within Meta, we were able to assist other forward-looking efforts and pave the way for the required collaborations across different organizations within the company.</p>

      <ul class="bullets">
        <li>Defined requirements of meshes to be displayed</li>
        <li>Led engineering efforts to identify mesh generation solution</li>
        <li>Identified critical launch features to define MVP</li>
      </ul>


    </div>
  </div>




</div>


<div class="footer">
  <p style="width:100%; text-align: center;"><a href="mailto:stv@stvmrshll.com">stv@stvmrshll.com</a></p>

</div>



<script type="text/javascript">
  
  myID = document.getElementById("project-nav");

  var myScrollFunc = function() {
    var y = window.scrollY;
    if (y >= 740) {
      myID.className = "float-nav show"
    } else {
      myID.className = "float-nav hide"
    }
  };

  window.addEventListener("scroll", myScrollFunc);

</script>

  </body>
</html>
